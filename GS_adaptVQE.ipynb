{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47550c7a-bf8c-4aff-b7b8-91f99cd3bb70",
   "metadata": {},
   "source": [
    "# Ground State Preparation of SU(2) Lattice Gauge Theory in Quantum Computer\n",
    "\n",
    "[Kogut-Susskind Hamiltonian](https://journals.aps.org/prd/abstract/10.1103/PhysRevD.11.395) for SU(2) Gauge Theory is:\n",
    "$$\n",
    "H = \\frac{g^2}{2}\\sum_{\\rm links} (E_i^a)^2 - \\frac{2}{a^2g^2} \\sum_{\\rm plaquettes} Z({\\bf n}) \\,,\n",
    "$$\n",
    "where, a in the denominator is the lattice spacing and in the superscript denotes SU(2) gauge group indices that are implicitly summer over, g is the gauge coupling constant with mass dimension $[g] = 0.5$ in 2+1 dimensions, $i = x$ or $y$ denotes spatial directions (implicitly summed), $\\bf{n} = (n_x, n_y)$ is a a lattice point and $Z(\\bf{n})$ is the plaquette operator, $E_i^a$ is the electric field along $i$th spatial direction associated with gauge group index $a$. \n",
    "\n",
    "**Mapping onto Spin Chain:**\n",
    "The Hamiltonian of the SU(2) gauge theory on a plaquette chain with a basis truncated at $j=1/2$ can be mapped onto a quantum spin chain, shown in \n",
    "$$ H = \\frac{3}{2}g^2\\sum_{i=0}^{N-1}\\frac{\\sigma_i^z+1}{2} - \\frac{3}{4}g^2\\sum_{i=0}^{N-1}\\frac{\\sigma_i^z+1}{2}\\frac{\\sigma_{i+1}^z+1}{2} - \\frac{2}{a^2g^2} \\sum_{i=0}^{N-1} \\big(-0.5\\big)^{\\frac{\\sigma_{i-1}^z+\\sigma_{i+1}^z+ 2}{2}}\n",
    "\\sigma_i^x \\,.$$\n",
    "Up to an irrelevant constant, this Hamiltonian can be rewritten as (see Ref. [1](https://arxiv.org/abs/2103.05179) and [2](https://arxiv.org/abs/2205.09247)} for a similar expression)\n",
    "$$ H_{tot} = J \\sum_{i=0}^{N-1}\\sigma_i^z\\sigma_{i+1}^z + h_z \\sum_{i=0}^{N-1}\\sigma_i^z + h_x \\sum_{i=0}^{N-1} \\frac{1-3\\sigma_{i-1}^z}{4} \\frac{1-3\\sigma_{i+1}^z}{4} \\sigma_i^x \\, ,$$\n",
    "\n",
    "That is,\n",
    "$$ H_{tot} = J \\sum_{i=0}^{N-1}\\sigma_i^z\\sigma_{i+1}^z + h_z \\sum_{i=0}^{N-1}\\sigma_i^z + \\frac{h_x}{16} \\sum_{i=0}^{N-1} ( \\sigma_i^x - 3\\sigma_{i-1}^z \\sigma_i^x - 3\\sigma_i^x\\sigma_{i+1}^z + 9 \\sigma_{i-1}^z \\sigma_i^x \\sigma_{i+1}^z )$$\n",
    "\n",
    "\n",
    "where $J = -3 g^2/16$, $h_z=3 g^2/8$ and $h_x = -2/(ag)^2$. Under the **periodic boundary condition**, $\\sigma_N^i=\\sigma_0^i$. The Hamiltonian is rescaled to be unitless and so are the parameters $J$, $h_z$ and $h_x$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b953bc5-dead-4e68-b7a2-8bd32e6e7d0e",
   "metadata": {},
   "source": [
    "## ADAPT-VQE Algorithm for the Interacting Ground State Preparation\n",
    "\n",
    "Here, we plan to use ADAPT-VQE algorithm for the ground state preparation of the SU(2) gauge theory in the quantum computer. Find reference here, [ADAPT (Adaptive Derivative-Assembled Problem-Tailored)](https://www.nature.com/articles/s41467-019-10988-2).\n",
    "\n",
    "The total Hamiltonian is: $H = H_E + H_M$ where,\n",
    "\n",
    "Electric Hamiltonian:\n",
    "$$H_{E} = J \\sum_{i=0}^{N-1}\\sigma_i^z\\sigma_{i+1}^z + h_z \\sum_{i=0}^{N-1}\\sigma_i^z$$\n",
    "\n",
    "\n",
    "Magnetic Hamiltonian:\n",
    "$$H_M = \\frac{h_x}{16} \\sum_{i=0}^{N-1} ( \\sigma_i^x - 3\\sigma_{i-1}^z \\sigma_i^x - 3\\sigma_i^x\\sigma_{i+1}^z + 9 \\sigma_{i-1}^z \\sigma_i^x \\sigma_{i+1}^z )$$\n",
    "\n",
    "That is in terms of Pauli's (X, Z),\n",
    "$$ H_{tot} = \\sum_{i=0}^{N-1}  [J Z_i Z_{i+1} + h_z Z_i + \\frac{h_x}{16} ( X_i - 3 Z_{i-1} X_i - 3 X_i Z_{i+1} + 9 Z_{i-1} X_i Z_{i+1})]$$\n",
    "\n",
    "where, $J = -3 g^2/16$, $h_z=3 g^2/8$ and $h_x = -2/(ag)^2$. Under the **periodic boundary condition**, $\\sigma_N^i=\\sigma_0^i$. The Hamiltonian is rescaled to be unitless and so are the parameters $J$, $h_z$ and $h_x$.\n",
    "\n",
    "\n",
    "Now, let us define the hamiltonian denstiy as,\n",
    "$ H_i = h_z Z_i + J/2 (Z_i Z_{i+1} + Z_{i-1} Z_i) + hx/16 * (X_i - 3 Z_{i-1} X_i - 3 X_i Z_{i+1} + 9 Z_{i-1} X_i Z_{i+1}) $\n",
    "\n",
    "\n",
    "**ADAPT-VQE Algorithm:**\n",
    "\n",
    "**Step 1:** Construct a pool of operators $\\{\\hat{O}_1, \\hat{O}_2, ..., \\hat{O}_k\\}$ constrained by the symmetry of the system. \n",
    "\n",
    "The ADAPT-VQE depends on the choice of an efficient and scalable pool of operators. The operators need to be imaginary and anti-symmetric.\n",
    "\n",
    "\n",
    "First, from the total hamiltonian, we can construct the operator pool $\\{\\hat{A}_1, \\hat{A}_2, ..., \\hat{A}_k\\}$ that is not \"imaginary and antisymmetric\", taking the proper commutation of which we can get the operator pool $\\{\\hat{O}_1, \\hat{O}_2, ..., \\hat{O}_k\\}$. Let's define the (real) operator pool as:\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{A}_1 &= Z_i \\\\\n",
    "\\hat{A}_2 &= Z_i Z_{i+1} \\\\\n",
    "\\hat{A}_3 &= X_i \\\\\n",
    "\\hat{A}_4 &= Z_{i-1} X_i \\\\\n",
    "\\hat{A}_5 &= X_i Z_{i+1} \\\\\n",
    "\\hat{A}_6 &= Z_{i-1} X_i Z_{i+1}\n",
    "\\end{align*}\n",
    "\n",
    "Then, the operator pool to be used in ADAPT-VQE is:\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{O}_1 &= Y_i \\\\\n",
    "\\hat{O}_2 &= Y_i Z_{i+1} \\\\\n",
    "\\hat{O}_3 &= Z_i Y_{i+1} \\\\\n",
    "\\hat{O}_4 &= Z_{i-1} Y_i Z_{i+1} \n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "**Step 2:** On the quantum device, initialize the quantum circuit the the current ansatz $\\ket{\\psi_{ansatz}}$ with desired quantum numbers and the symmetries of the target. The ansatz is dynamically created: $\\cdots e^{i \\theta_3  \\hat{O}_3}e^{i \\theta_2 \\hat{O}_2}e^{i \\theta_1 \\hat{O}_1} \\ket{\\psi_{ref}}$. Here, in our case, let's take the ground state of the electric part of the total hamiltonian as our reference state: $\\ket{\\psi_{ref}} = \\ket{11111 \\cdots 11111}$ (all spins down -- obtained by applying X-gate to the initialized (at 0) quantum circuit).\n",
    "\n",
    "**Step 3:** Each time add one operator that gives the largest gradient magnitude.\n",
    "\n",
    "Measure the energy gradient $\\frac{\\partial E}{\\partial \\theta_i} |_{\\theta_i=0}$ with respect to the variational parameter $\\theta_i$ of the candidate pool operator $\\hat{A}$. Repeat this step for every pool operator. Here, we measure the expectation value of the commutator of hamiltonian with each operator in the pool $\\braket{\\psi^{(k)}_{ansatz}|[\\hat{H},\\hat{O_i}]|\\psi^{(k)}_{ansatz}} = \\frac{\\partial E}{\\partial \\theta_i} |_{\\theta_i=0} = [\\frac{\\partial }{\\partial \\theta_i} \\braket{\\psi^{(k)}_{ansatz}|e^{-i \\theta_i \\hat{O}_i}H e^{i \\theta_i \\hat{O}_i}|\\psi^{(k)}_{ansatz}}]|_{\\theta_i=0}$ which gives the estimate of decrease in the energy by transforming the ansatz wavefunction from $\\ket{\\psi_{ansatz}} \\rightarrow e^{i \\theta_i \\hat{O}}\\ket{\\psi_{ansatz}}$.\n",
    "\n",
    "That is to say, add the operator $\\hat{P}_n$ with the largest gradient norm to the ansatz with its variational parameter set to zero.\n",
    "\n",
    "**Step 4:** Perform ordinary VQE to update all ansatz parameters. \n",
    "\n",
    "**Step 5:** Repeat steps 1 to 4 until convergence. That is if the measured expectation value is less than the tolerance/threshold $(\\epsilon)$, then algorithm terminates as the ADAPT-VQE has converged.\n",
    "\n",
    "\n",
    "After adding the operators, after k-th iteration, the ansatz has the form:\n",
    "\n",
    "$\\ket{\\psi_k} = e^{i \\theta_k \\hat{O}_k}.....e^{i \\theta_2 \\hat{O}_2} e^{i \\theta_1 \\hat{O}_1} \\ket{\\psi_0} $,\n",
    "\n",
    "and the energy gradient with respect to the variational parameter of the candidate operator $\\hat{O}_i$, $\\theta_i$ in the $(k+1)-th$ iteration, using the antihermiticity of the pool operators becomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20a84f52-bda1-423f-8aa8-ae4fd1aa1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## INSTALLATIONS REQUIRED\n",
    "# !pip install qiskit[visualization]==1.1.0\n",
    "# !pip install qiskit_aer\n",
    "# !pip install qiskit qiskit-aer\n",
    "# !pip install scipy\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install qiskit-ibm-runtime\n",
    "# !pip install -U sympy\n",
    "# !pip install distinctipy\n",
    "# !pip install pylatexenc\n",
    "# !pip install prototype-zne\n",
    "# !pip install physics-tenpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50de28dc-e2b0-4be5-b0f2-61552ffa3ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qiskit\n",
    "qiskit.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62e02f9c-ffa9-4f42-ad83-b68dde5ab311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import scipy.linalg as LA\n",
    "from scipy.linalg import eig, eigh\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import minimize, basinhopping\n",
    "from qiskit import *\n",
    "import matplotlib.pyplot as plt\n",
    "import distinctipy\n",
    "import matplotlib.ticker as ticker\n",
    "from qiskit.quantum_info import Pauli, SparsePauliOp\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit.visualization import state_visualization\n",
    "from qiskit.circuit import QuantumCircuit, Parameter\n",
    "import qiskit.quantum_info as qi\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit.visualization import plot_histogram, plot_state_city\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, EstimatorV2, Batch\n",
    "from qiskit_ibm_runtime.options import EstimatorOptions, DynamicalDecouplingOptions\n",
    "from qiskit.transpiler import CouplingMap\n",
    "from qiskit.primitives import StatevectorEstimator, Estimator as AerEstimator\n",
    "# from qiskit_ibm_runtime.fake_provider import FakeManilaV2\n",
    "# from qiskit.primitives import BackendEstimator\n",
    "# from qiskit.providers.fake_provider import GenericBackendV2\n",
    "\n",
    "# from qiskit_ibm_runtime import QiskitRuntimeService, Session, EstimatorV2 as Estimator\n",
    "\n",
    "## DMRG\n",
    "# import tenpy\n",
    "# from tenpy.networks.mps import MPS\n",
    "# from tenpy.models.lattice import Chain\n",
    "# from tenpy.models.spins import SpinModel\n",
    "# from tenpy.algorithms.dmrg import dmrg\n",
    "# from tenpy.tools.params import get_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cd1ea64-33d6-4d90-88cb-fe72127622da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HAMILTONIAN WITH PERIODIC BOUNDARY CONDITIONS\n",
    "# the electric part of the Hamiltonian\n",
    "def hamiltonian_elec(N, J, hz):\n",
    "    \"\"\"\n",
    "    Constructs the electronic part of the Hamiltonian H_E for a system of N spins.\n",
    "\n",
    "    Parameters: \n",
    "    N (int): Number of spins\n",
    "    J (float): constant\n",
    "    hz (float): another constant\n",
    "\n",
    "    Returns:\n",
    "    SparsePauliOp: SparsePauliOp object representing the electronic part of the Hamiltonian\n",
    "    \"\"\"\n",
    "    pauli_list = []\n",
    "    coeffs = []\n",
    "    \n",
    "    # Constructing the linear terms hz * sum(sigma_i^z)\n",
    "    for i in range(N):\n",
    "        z_term = ['I'] * N\n",
    "        z_term[i] = 'Z'\n",
    "        pauli_list.append(Pauli(''.join(z_term))) \n",
    "        coeffs.append(hz)\n",
    "    \n",
    "    # Constructing the interaction terms J * sum(sigma_i^z * sigma_{i+1}^z)\n",
    "    for i in range(N):\n",
    "        z_term = ['I'] * N\n",
    "        z_term[i] = 'Z'\n",
    "        z_term[(i + 1) % N] = 'Z'\n",
    "        pauli_list.append(Pauli(''.join(z_term))) \n",
    "        coeffs.append(J)\n",
    "    \n",
    "    # Create SparsePauliOp for the Hamiltonian\n",
    "    H_E = SparsePauliOp(pauli_list, coeffs)\n",
    "\n",
    "    return H_E.simplify()\n",
    "\n",
    "## magnetic hamiltonian\n",
    "def hamiltonian_mag(N, hx):\n",
    "    \"\"\"\n",
    "    Constructs the magnetic part of the Hamiltonian H_B for a system of N spins.\n",
    "    \n",
    "    Parameters:\n",
    "    N (int): Number of spins\n",
    "    hx (float): Constant parameter hx\n",
    "\n",
    "    Returns:\n",
    "    SparsePauliOp: SparsePauliOp object representing the magnetic part of the Hamiltonian\n",
    "    \"\"\"\n",
    "    pauli_list = []\n",
    "    coeffs = []\n",
    "\n",
    "    factor = hx / 16\n",
    "\n",
    "    for i in range(N):\n",
    "        # Term: sigma_i^x\n",
    "        x_term = ['I'] * N\n",
    "        x_term[i] = 'X'\n",
    "        pauli_list.append(Pauli(''.join(x_term)))\n",
    "        coeffs.append(factor)\n",
    "\n",
    "        # Term: -3 * sigma_{i-1}^z * sigma_i^x\n",
    "        zx_term = ['I'] * N\n",
    "        zx_term[(i-1) % N] = 'Z'\n",
    "        zx_term[i] = 'X'\n",
    "        pauli_list.append(Pauli(''.join(zx_term)))\n",
    "        coeffs.append(-3 * factor)\n",
    "\n",
    "        # Term: -3 * sigma_i^x * sigma_{i+1}^z\n",
    "        xz_term = ['I'] * N\n",
    "        xz_term[i] = 'X'\n",
    "        xz_term[(i+1) % N] = 'Z' #periodic boundary condition (imposed by % sign)\n",
    "        pauli_list.append(Pauli(''.join(xz_term)))\n",
    "        coeffs.append(-3 * factor)\n",
    "\n",
    "        # Term: 9 * sigma_{i-1}^z * sigma_i^x * sigma_{i+1}^z\n",
    "        zxz_term = ['I'] * N\n",
    "        zxz_term[(i-1) % N] = 'Z'\n",
    "        zxz_term[i] = 'X'\n",
    "        zxz_term[(i+1) % N] = 'Z'\n",
    "        pauli_list.append(Pauli(''.join(zxz_term)))\n",
    "        coeffs.append(9 * factor)\n",
    "\n",
    "    # Create SparsePauliOp for the Hamiltonian\n",
    "    H_M = SparsePauliOp(pauli_list, coeffs)\n",
    "\n",
    "    return H_M.simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34dcbaa3-82c2-42d3-bda2-97d0b0101e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIND EXACT GROUND STATE OF HAMILTONIAN ###\n",
    "def exact_ground_state(H):\n",
    "    \"\"\"\n",
    "    Find the exact ground state of the Hamiltonian H.\n",
    "\n",
    "    Parameters:\n",
    "    - H: The Hamiltonian operator.\n",
    "\n",
    "    Returns:\n",
    "    - eigenvals: all the eigenvalues of H\n",
    "    - eigenvecs: all the eigenvectors of H\n",
    "    - energy_realgs: The ground state energy.\n",
    "    - psi_realgs: The ground state vector.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute Hamiltonian matrix\n",
    "    H_matrix = H.to_matrix()  # H is a qiskit operator (defined above)\n",
    "\n",
    "    # Classical ground state calculation (real GS) using scipy.linalg.eigh\n",
    "    #eigenvals, eigenvecs = eig(H_matrix,right=True)   \n",
    "    eigenvals, eigenvecs = eigh(H_matrix)\n",
    "    \n",
    "    # Find the ground state (eigenvector with the smallest eigenvalue)\n",
    "    index_gs = np.argmin(eigenvals)\n",
    "    energy_realgs = eigenvals[index_gs]\n",
    "    psi_realgs = eigenvecs[:,index_gs] # Extract the eigenvector (column) corresponding to the smallest eigenvalue\n",
    "    '''Return the eigenvalues and eigenvectors of a complex Hermitian (conjugate symmetric) \n",
    "    or a real symmetric matrix. Returns two objects, a 1-D array containing the eigenvalues of a, \n",
    "    and a 2-D square array or matrix (depending on the input type) of the \n",
    "    corresponding eigenvectors (in columns).'''\n",
    "    \n",
    "    # Normalize the ground state vector (optional)\n",
    "    psi_realgs /= np.linalg.norm(psi_realgs)\n",
    "\n",
    "    return eigenvals, eigenvecs, energy_realgs, psi_realgs\n",
    "\n",
    "# find the overlap\n",
    "def calc_overlap(psi_final, psi_realgs):\n",
    "    #psi_final = Statevector(psi_final)\n",
    "    # Convert psi_final to numpy array if it's not already\n",
    "    psi_final = np.asarray(psi_final)\n",
    "    psi_realgs = np.asarray(psi_realgs)\n",
    "    \n",
    "    psi_realgs_normal = psi_realgs / np.linalg.norm(psi_realgs)\n",
    "    \n",
    "    psi_final_normal = psi_final / np.linalg.norm(psi_final)\n",
    "    \n",
    "    overlap = np.abs(np.dot(psi_realgs_normal.conj(), psi_final_normal))**2\n",
    "    \n",
    "    return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e2bb1e5-724c-43ce-9554-462f82718a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define OBSERVABLE POOL {Y_i, Y_i Z_{i+1}, Z_i Y_{i+1}, Z_{i-1} Y_i Z_{i+1}}\n",
    "def define_operator_pool(lattice_site, N):\n",
    "    \"\"\"\n",
    "    Define the operator pool for a given lattice site and number of qubits.\n",
    "    \n",
    "    Parameters:\n",
    "    lattice_site (int): The index of the lattice site to apply the observable.\n",
    "    N (int): The number of qubits (spins).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where the keys are observable names and the values are SparsePauliOp objects.\n",
    "    \"\"\"\n",
    "    def create_pauli_op(pauli_string, indices):\n",
    "        \"\"\"Helper function to create a SparsePauliOp for given indices.\"\"\"\n",
    "        pauli_list = ['I'] * N\n",
    "        for index, pauli in zip(indices, pauli_string):\n",
    "            wrapped_index = index % N  # Wrap around for periodicity\n",
    "            pauli_list[wrapped_index] = pauli\n",
    "        return SparsePauliOp(Pauli(''.join(pauli_list)))\n",
    "\n",
    "    # Define operator_pool with periodic boundary conditions\n",
    "    operator_pool = {\n",
    "        'Y': create_pauli_op('Y', [lattice_site]),\n",
    "        'YZ': create_pauli_op('YZ', [lattice_site]),\n",
    "        'ZY': create_pauli_op('ZY', [lattice_site, lattice_site + 1]),\n",
    "        'ZYZ': create_pauli_op('ZYZ', [lattice_site - 1, lattice_site, lattice_site + 1]),\n",
    "    }\n",
    "\n",
    "    return operator_pool\n",
    "\n",
    "## APPLY UNITARY BASED ON THE OBSERVABLE INDEX\n",
    "def apply_unitary(ansatz, lattice_site, theta_vals, operator_index):\n",
    "    \"\"\"\n",
    "    Define unitary operations (into the quantum circuit) for the given operator pool.\n",
    "\n",
    "    Parameters:\n",
    "    qc: quantum circuit where we want to apply the unitary operator to\n",
    "    lattice_site: where to apply unitary\n",
    "    theta_vals: optimized parameter values [theta_1 for Y, theta_2 for YZ, theta_3 for ZY, theta_4 for ZYZ]\n",
    "    obs_index: index of the observable in the observable pool\n",
    "\n",
    "    Returns: quantum circuit after applying unitary corresponding to the observable index (in the observable pool)\n",
    "    \"\"\"\n",
    "    # No of qubits\n",
    "    N = ansatz.num_qubits\n",
    "\n",
    "    qc = ansatz\n",
    "    \n",
    "    theta_vals = [Parameter(\"theta_0\"), Parameter(\"theta_1\"), Parameter(\"theta_2\"), Parameter(\"theta_3\")]\n",
    "    \n",
    "    # Operator pool\n",
    "    operator_pool = define_operator_pool(lattice_site, N) \n",
    "\n",
    "    # Ensure observable_index is within range\n",
    "    if operator_index >= len(operator_pool):\n",
    "        print(f\"Operator index {operator_index} is out of range for the operator pool.\")\n",
    "        return qc\n",
    "        \n",
    "    # If within range, proceed\n",
    "    name = list(operator_pool.keys())[operator_index]\n",
    "\n",
    "    # Print the theta_vals\n",
    "    # print(\"=\"*25)\n",
    "    # print(f\"Parameters, theta vals: {theta_vals}\")\n",
    "    # print(\"=\"*25)\n",
    "    \n",
    "    # Apply unitary operations for each operator\n",
    "    if name == 'Y': # exp(i theta_1 Y); Y = (HS) Z (HS)^dag\n",
    "        qc.rz(-2 * theta_vals[operator_index], lattice_site)\n",
    "\n",
    "        print(\"=\"*25)\n",
    "        print(f\"==> Applied Unitary: exp(-i ({theta_vals[operator_index]}) {name})\")\n",
    "        print(\"=\"*25)\n",
    "\n",
    "    elif name == 'YZ':  # exp(i theta_2 YZ); YZ = (HS) ZZ (HS)^dagger\n",
    "        i, j = lattice_site, (lattice_site + 1) % N\n",
    "        qc.h(i)\n",
    "        qc.s(i)\n",
    "        qc.cx(i, j)\n",
    "        qc.rz(-2 * theta_vals[operator_index], j)\n",
    "        qc.cx(i, j)\n",
    "        qc.sdg(i)\n",
    "        qc.h(i)\n",
    "\n",
    "        print(\"=\"*25)\n",
    "        print(f\"==> Applied Unitary: exp(-i ({theta_vals[operator_index]}) {name})\")\n",
    "        print(\"=\"*25)\n",
    "\n",
    "    elif name == 'ZY': # exp(i theta_3 ZY)\n",
    "        i, j = lattice_site, (lattice_site + 1) % N\n",
    "        qc.h(j)\n",
    "        qc.s(j)\n",
    "        qc.cx(i, j)\n",
    "        qc.rz(-2 * theta_vals[operator_index], j)\n",
    "        qc.cx(i, j)\n",
    "        qc.sdg(j)\n",
    "        qc.h(j)\n",
    "\n",
    "        print(\"=\"*25)\n",
    "        print(f\"==> Applied Unitary: exp(-i ({theta_vals[operator_index]}) {name})\")\n",
    "        print(\"=\"*25)\n",
    "\n",
    "    elif name == 'ZYZ': # exp(i theta_4 ZYZ)\n",
    "        i, j, k = (lattice_site - 1) % N, lattice_site, (lattice_site + 1) % N\n",
    "        qc.h(j)\n",
    "        qc.s(j)\n",
    "        qc.cx(i,j)\n",
    "        qc.cx(j,k)\n",
    "        qc.rz(-2 * theta_vals[operator_index], k)\n",
    "        qc.cx(j,k)\n",
    "        qc.cx(i,j)\n",
    "        qc.sdg(j)\n",
    "        qc.h(j)\n",
    "\n",
    "        print(\"=\"*25)\n",
    "        print(f\"==> Applied Unitary: exp(-i ({theta_vals[operator_index]}) {name})\")\n",
    "        print(\"=\"*25)\n",
    "    \n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5ee460c-6ac1-4bb3-b069-daf7f46ebe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions to Measure Expectation Value \n",
    "def measure_exact_expectation_value(qc, observable):\n",
    "    # print(\"Computing exact expectation value for observables\")\n",
    "    \n",
    "    # ## Ref: https://docs.quantum.ibm.com/guides/simulate-with-qiskit-aer\n",
    "    aer_sim = AerSimulator(method=\"automatic\")\n",
    "    pm = generate_preset_pass_manager(1, AerSimulator())\n",
    "    isa_qc = pm.run(qc)\n",
    "    isa_observable = observable.apply_layout(isa_qc.layout)\n",
    "\n",
    "    ## ## USING QISKIT.PRIMITIVES ESTIMATOR: EXACT\n",
    "    ## (SHOTS = NONE Gives Exact: https://docs.quantum.ibm.com/api/qiskit/qiskit.primitives.Estimator)\n",
    "    est_exact = AerEstimator() \n",
    "    job_exact = est_exact.run(isa_qc, isa_observable, parameter_values=None, shots=None)\n",
    "    result_exact = job_exact.result()\n",
    "    exact_exp = result_exact.values[0]\n",
    "\n",
    "    return exact_exp\n",
    "\n",
    "## FIND THE COMMUTATORS [H_total, A_i]: USED TO GET THE GRADIENT OF ENERGY\n",
    "def commutator_pauli(op1, op2):\n",
    "    \"\"\"\n",
    "    ### Compute the commutator [op1, op2] where op1 and op2 are SparsePauliOps.    \n",
    "    Parameters:\n",
    "    op1 (SparsePauliOp): The first Pauli operator.\n",
    "    op2 (SparsePauliOp): The second Pauli operator.\n",
    "    ### Returns:\n",
    "    SparsePauliOp: The commutator [op1, op2].\n",
    "    \"\"\"\n",
    "    # commutator is [op1, op2] = op1 * op2 - op2 * op1\n",
    "    comm = op1 @ op2 - op2 @ op1\n",
    "    return comm.simplify()\n",
    "\n",
    "def commutator_hamiltonian(H_total, operator_pool):\n",
    "    \"\"\"\n",
    "    Calculate the commutator [H_total, A_i] for each operator in the observable pool.\n",
    "    \n",
    "    Parameters:\n",
    "    H_total (SparsePauliOp): The total Hamiltonian.\n",
    "    operator_pool (dict): The dictionary of operators {O_i}.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with commutators [H_total, O_i] for each operator O_i in the operator pool.\n",
    "    \"\"\"\n",
    "    commutators = {}\n",
    "    \n",
    "    for operator_name, operator in operator_pool.items():\n",
    "        comm = None  # Start with None to accumulate terms\n",
    "        for h_term, h_coeff in zip(H_total.paulis, H_total.coeffs):\n",
    "            for a_term, a_coeff in zip(operator.paulis, operator.coeffs):\n",
    "                # Compute commutator of individual terms\n",
    "                comm_term = commutator_pauli(SparsePauliOp([h_term], [h_coeff]), SparsePauliOp([a_term], [a_coeff]))\n",
    "                \n",
    "                # Accumulate commutators\n",
    "                if comm is None:\n",
    "                    comm = comm_term\n",
    "                else:\n",
    "                    comm += comm_term\n",
    "        \n",
    "        commutators[operator_name] = comm.simplify()\n",
    "        \n",
    "        # print(\"=\"*50)\n",
    "        # print(f\"[H_total, {operator_name}]: {comm.simplify()}\")\n",
    "        # print(\"=\"*50)    \n",
    "    return commutators\n",
    "    \n",
    "# measure gradient\n",
    "def measure_gradient(H_total, operator_pool, qc):\n",
    "    \"\"\"\n",
    "    Measure the gradient\n",
    "    \n",
    "    Parameters:\n",
    "    H_total (SparsePauliOp): The total Hamiltonian.\n",
    "    observable_pool (dict): Dictionary of observables {O_1, O_2, O_3, O_4}.\n",
    "    qc (QuantumCircuit): Quantum circuit to measure expectation values.\n",
    "    shots (int): Number of shots for statistical measurements.\n",
    "    exact_cache (dict): Cache for exact expectation values.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with (the norm of) gradients for each operator.\n",
    "    \"\"\"\n",
    "    \n",
    "    gradients = {}\n",
    "\n",
    "    # Calculate commutators [H_total, O_i] for all operators in the pool\n",
    "    commutators = commutator_hamiltonian(H_total, operator_pool)\n",
    "    \n",
    "    for operator_name, comm in commutators.items():\n",
    "        # check if the comm is hermitian of not\n",
    "        # comm_matrix = comm.to_matrix()\n",
    "        # print(f\"For [H_tot, {operator_name}], Hermitian: \", np.allclose(comm_matrix, comm_matrix.conj().T))\n",
    "        \n",
    "        # Measure expectation value of the commutator\n",
    "        exact_exp = measure_exact_expectation_value(qc, comm)\n",
    "        \n",
    "        ## gradient is the expectation value of the commutator [H_tot, A_i]\n",
    "        ## taking norm for the expectation value: gradient\n",
    "        gradients[operator_name] = np.linalg.norm(exact_exp)\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65d43e2d-3124-4e50-8bdb-9c116dc7c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating the Cost Function For VQE (Optimization of Parameters for min Cost)\n",
    "cost_history_dict = {\n",
    "    \"prev_vector\": None,\n",
    "    \"iters\": 0,\n",
    "    \"cost_history\": [],\n",
    "}\n",
    "\n",
    "# Updating the cost function to accept theta_vals as the first argument\n",
    "# def cost_function(theta_vals, hamiltonian, ansatz):\n",
    "#     print(\"--\"*10)\n",
    "#     print(f\"Initial Params: {theta_vals}\")\n",
    "#     print(\"--\"*10)\n",
    "    \n",
    "#     cost_value = measure_exact_expectation_value(ansatz, hamiltonian)\n",
    "\n",
    "#     cost_history_dict[\"iters\"] += 1\n",
    "#     cost_history_dict[\"prev_vector\"] = theta_vals\n",
    "#     cost_history_dict[\"cost_history\"].append(cost_value)\n",
    "#     print(f\"Iters. done: {cost_history_dict['iters']} [Current cost: {cost_value}]\")\n",
    "\n",
    "#     return cost_value\n",
    "\n",
    "# def cost_func_vqe(theta_vals, hamiltonian, ansatz):\n",
    "#     \"\"\"Return estimate of energy from estimator\n",
    "\n",
    "#     Parameters:\n",
    "#         params (ndarray): Array of ansatz parameters\n",
    "#         ansatz (QuantumCircuit): Parameterized ansatz circuit\n",
    "#         hamiltonian (SparsePauliOp): Operator representation of Hamiltonian\n",
    "\n",
    "#     Returns:\n",
    "#         float: Energy estimate\n",
    "#     \"\"\"   \n",
    "#     print(\"--\"*10)\n",
    "#     print(f\"Current Params: {theta_vals}\")\n",
    "#     print(\"--\"*10)\n",
    "    \n",
    "#     ### <psi(theta) | H_total | psi(theta)>\n",
    "#     estimator = Estimator()\n",
    "#     pub = (ansatz, hamiltonian, theta_vals)\n",
    "#     job = estimator.run([pub])\n",
    "#     # Extract the result for the 0th pub (this example only has one pub)\n",
    "#     cost = job.result()[0].data.evs\n",
    "\n",
    "#     cost_value = cost[0]\n",
    "\n",
    "#     cost_history_dict[\"iters\"] += 1\n",
    "#     cost_history_dict[\"prev_vector\"] = theta_vals\n",
    "#     cost_history_dict[\"cost_history\"].append(cost_value)\n",
    "#     print(f\"Iters. done: {cost_history_dict['iters']} [Current cost: {cost_value}]\")\n",
    "\n",
    "#     return cost_value\n",
    "\n",
    "def cost_func_vqe(theta_vals, hamiltonian, ansatz):\n",
    "    \"\"\"Return estimate of energy from estimator\n",
    "\n",
    "    Parameters:\n",
    "        params (ndarray): Array of ansatz parameters\n",
    "        ansatz (QuantumCircuit): Parameterized ansatz circuit\n",
    "        hamiltonian (SparsePauliOp): Operator representation of Hamiltonian\n",
    "        estimator (Estimator): Estimator primitive instance\n",
    "\n",
    "    Returns:\n",
    "        float: Energy estimate\n",
    "    \"\"\"\n",
    "    print(\"Initial Params\", theta_vals)\n",
    "    \n",
    "    estimator = StatevectorEstimator()\n",
    "    pub = (ansatz, hamiltonian, theta_vals)\n",
    "    cost = estimator.run([pub]).result()[0].data.evs\n",
    "\n",
    "    print(\"Cost: \", cost)\n",
    "#    cost = estimator.run(ansatz, hamiltonian, parameter_values=params).result().values[0]\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5fd492b-cb5c-4bd3-8eb2-208f6d364af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The ground state (electric hamiltonian) as the initial ref state\n",
    "## Let's make this the reference state\n",
    "def initial_ref(N):\n",
    "    circ = QuantumCircuit(N) #all in 0 states (up)\n",
    "    for i in range(N):\n",
    "        circ.x(i) #all 1 states #all down\n",
    "    circ.barrier()\n",
    "    # psi_known_gs = qi.Statevector.from_instruction(circ) # Quantum Index    \n",
    "  \n",
    "    #return circ, psi_known_gs\n",
    "    return circ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22354c76-cf37-44be-8b0b-2e3abe503c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## CHECKING PREVIOUS FUNCTIONS: WORKS GOOD UNTIL HERE\n",
    "\n",
    "# ### Define constants\n",
    "# N = 5  # Number of spins\n",
    "# a = 1.0  # Lattice spacing\n",
    "# lattice_site = 0\n",
    "\n",
    "# # coupling constants \n",
    "# g = 2.0\n",
    "\n",
    "# # Calculate Hamiltonian parameters\n",
    "# J = -3 * g**2 / 16\n",
    "# hz = 3 * g**2 / 8\n",
    "# hx = -2 / (a * g)**2  \n",
    "\n",
    "# # Calculate Hamiltonian\n",
    "# H_elec = hamiltonian_elec(N, J, hz)\n",
    "# H_mag = hamiltonian_mag(N, hx)\n",
    "# H_tot = H_elec + H_mag\n",
    "\n",
    "# # ### FIND EXACT GROUND STATE OF HAMILTONIAN ###\n",
    "# print(\"========= Exact GS =========\")\n",
    "# _, _, energy_realgs, _ = exact_ground_state(H_tot)  \n",
    "# print(\"Exact Ground State Energy of The Total Hamiltonian: \", energy_realgs)\n",
    "\n",
    "# # ref state (or initial_ansatz)\n",
    "# initial_ansatz = initial_ref(N)\n",
    "\n",
    "# ## Calculate the Gradient\n",
    "# print(\"===============>>> Calculate the Gradients (Norm) <<<===================\")\n",
    "# operator_pool = define_operator_pool(lattice_site, N)\n",
    "# gradients = measure_gradient(H_tot, operator_pool, initial_ansatz)\n",
    "# print(\"Gradients: \", gradients)\n",
    "# print(\"Maximum Gradient: \", np.max(list(gradients.values())))\n",
    "# max_grad_op_idx = np.argmax(list(gradients.values()))\n",
    "\n",
    "# # Parameters\n",
    "# # theta_vals = [Parameter(\"theta_0\"), Parameter(\"theta_1\"), Parameter(\"theta_2\"), Parameter(\"theta_3\")] \n",
    "\n",
    "# print(\"===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\")\n",
    "# # Parameterized Ansatz After Applying Unitary corresponding to the Maximum gradient norm Operator \n",
    "# ansatz_to_optimize = apply_unitary(initial_ansatz, lattice_site, theta_vals, max_grad_op_idx)\n",
    "# print(\"Number of Parameters: \", ansatz_to_optimize.num_parameters)\n",
    "# print(ansatz_to_optimize.draw())\n",
    "\n",
    "# # Initial Parameters (Theta Values)\n",
    "# initial_theta_vals = [0.1]*ansatz_to_optimize.num_parameters\n",
    "# print(\"Checking Cost with Initial Params: \", cost_func_vqe(initial_theta_vals, H_tot, ansatz_to_optimize))\n",
    "  \n",
    "# ### PERFORM VQE: Optimizing the parameters: Minimize the Cost\n",
    "# ## scipy.optimize.minimize(func, x0, ...) or scipy.optimize.basinhopping\n",
    "# ## other options available: L-BFGS-B, COBYLA, BFGS, etc\n",
    "\n",
    "# # Initialize history tracking\n",
    "# cost_history = []\n",
    "# theta_history = {f'theta_{i}': [] for i in range(len(initial_theta_vals))}\n",
    "\n",
    "# def callback(x):\n",
    "#     energy = cost_func_vqe(x, H_tot, ansatz_to_optimize)\n",
    "#     cost_history.append(energy)\n",
    "#     for i, theta in enumerate(x):\n",
    "#         theta_history[f'theta_{i}'].append(theta)\n",
    "        \n",
    "# # Perform VQE Optimization\n",
    "# opt = minimize(cost_func_vqe, initial_theta_vals, args=(H_tot, ansatz_to_optimize), method='COBYLA', callback=callback)\n",
    "\n",
    "# print(\"Optimized Parameter: \", opt.x)\n",
    "# print(\"Optimized Energy: \", opt.fun)\n",
    "\n",
    "# optimized_theta_vals[max_grad_op_idx] = opt.x\n",
    "\n",
    "# # Apply optimized parameters to the ansatz\n",
    "# print(\"========= Applying Optimized Unitary =========\")\n",
    "# optimized_ansatz = ansatz_to_optimize.assign_parameters(opt.x) # bind parameters to create a bound circuit\n",
    "# print(\"Optimized Ansatz Circuit:\")\n",
    "# print(optimized_ansatz.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27c42796-e149-42b0-abad-86efb04445a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Spins (N): 5, Coupling (g) : 5.0\n",
      "====================================================================================================\n",
      "Exact Ground State Energy of The Total Hamiltonian:  -70.31335332427172\n",
      "Selected Lattice Site: 0\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:0\n",
      "Circuit Depth: 1\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.16, 'YZ': 0.16, 'ZY': 0.16, 'ZYZ': 0.16}\n",
      "Maximum Gradient:  0.16\n",
      "Operator with largest gradient: Y, Gradient: 0.16\n",
      "This is the first iteration, so no previous operator to compare with.\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_0) Y)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [-0.69718225]\n",
      "Cost:  -70.3125\n",
      "Initial Params [-0.69718224]\n",
      "Cost:  -70.3125\n",
      "Optimized theta values: [-0.69718225]\n",
      "Cost function after optimization: -70.3125\n",
      "Optimized Theta Values:  [-0.6971822506393264, 0, 0, 0]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 1 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:1\n",
      "Circuit Depth: 2\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.16, 'YZ': 0.16, 'ZY': 0.16, 'ZYZ': 0.16}\n",
      "Maximum Gradient:  0.16\n",
      "Operator with largest gradient: Y, Gradient: 0.16\n",
      "Warning: The current operator (Y) is the same as the last applied operator.\n",
      "Applying the second largest gradient operator instead: ZYZ, Gradient: 0.16\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_3) ZYZ)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [-2.34111206]\n",
      "Cost:  -50.996994643303566\n",
      "Initial Params [-2.34111205]\n",
      "Cost:  -50.99699426847418\n",
      "Initial Params [-3.34111206]\n",
      "Cost:  -68.83940385504175\n",
      "Initial Params [-3.34111205]\n",
      "Cost:  -68.83940400074157\n",
      "Initial Params [-3.34111206]\n",
      "Cost:  -68.83940385504175\n",
      "Initial Params [-3.06120497]\n",
      "Cost:  -70.07068979118745\n",
      "Initial Params [-3.06120496]\n",
      "Cost:  -70.07068973115608\n",
      "Initial Params [-3.06120497]\n",
      "Cost:  -70.07068979118745\n",
      "Initial Params [-3.14288051]\n",
      "Cost:  -70.31243780364967\n",
      "Initial Params [-3.1428805]\n",
      "Cost:  -70.31243780461556\n",
      "Initial Params [-3.14288051]\n",
      "Cost:  -70.31243780364967\n",
      "Initial Params [-3.14158719]\n",
      "Cost:  -70.31249999887942\n",
      "Initial Params [-3.14158718]\n",
      "Cost:  -70.3124999988753\n",
      "Initial Params [-3.14158719]\n",
      "Cost:  -70.31249999887942\n",
      "Initial Params [-3.14159268]\n",
      "Cost:  -70.31249999999993\n",
      "Initial Params [-3.14159267]\n",
      "Cost:  -70.31249999999996\n",
      "Initial Params [-3.14159268]\n",
      "Cost:  -70.31249999999993\n",
      "Optimized theta values: [-3.14159268]\n",
      "Cost function after optimization: -70.31249999999993\n",
      "Optimized Theta Values:  [-0.6971822506393264, 0, 0, -3.141592681937526]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 2 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:2\n",
      "Circuit Depth: 11\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.1599999999999997, 'YZ': 0.1599999999999997, 'ZY': 0.15999999999999992, 'ZYZ': 0.15999999999999984}\n",
      "Maximum Gradient:  0.15999999999999992\n",
      "Operator with largest gradient: ZY, Gradient: 0.15999999999999992\n",
      "The current operator (ZY) is different from the last applied operator (ZYZ).\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_2) ZY)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [-2.2049118]\n",
      "Cost:  -45.97556174408484\n",
      "Initial Params [-2.20491179]\n",
      "Cost:  -45.975561386119125\n",
      "Initial Params [-3.2049118]\n",
      "Cost:  -70.16235155688042\n",
      "Initial Params [-3.20491179]\n",
      "Cost:  -70.16235160424296\n",
      "Initial Params [-3.2049118]\n",
      "Cost:  -70.16235155688042\n",
      "Initial Params [-3.08806198]\n",
      "Cost:  -70.20514509561303\n",
      "Initial Params [-3.08806197]\n",
      "Cost:  -70.2051450555417\n",
      "Initial Params [-3.08806198]\n",
      "Cost:  -70.20514509561303\n",
      "Initial Params [-3.14161477]\n",
      "Cost:  -70.31249998166018\n",
      "Initial Params [-3.14161476]\n",
      "Cost:  -70.31249998167678\n",
      "Initial Params [-3.14161477]\n",
      "Cost:  -70.31249998166018\n",
      "Initial Params [-3.14159259]\n",
      "Cost:  -70.31249999999977\n",
      "Initial Params [-3.14159258]\n",
      "Cost:  -70.31249999999976\n",
      "Initial Params [-3.14159259]\n",
      "Cost:  -70.31249999999977\n",
      "Optimized theta values: [-3.14159259]\n",
      "Cost function after optimization: -70.31249999999977\n",
      "Optimized Theta Values:  [-0.6971822506393264, 0, -3.141592594918539, -3.141592681937526]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 3 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:3\n",
      "Circuit Depth: 18\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.15999999999999964, 'YZ': 0.15999999999999964, 'ZY': 0.1599999999999998, 'ZYZ': 0.15999999999999975}\n",
      "Maximum Gradient:  0.1599999999999998\n",
      "Operator with largest gradient: ZY, Gradient: 0.1599999999999998\n",
      "Warning: The current operator (ZY) is the same as the last applied operator.\n",
      "Applying the second largest gradient operator instead: ZYZ, Gradient: 0.15999999999999975\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_3) ZYZ)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [2.15271654]\n",
      "Cost:  -44.14095507038086\n",
      "Initial Params [2.15271655]\n",
      "Cost:  -44.14095541475461\n",
      "Initial Params [3.15271654]\n",
      "Cost:  -70.30785993285829\n",
      "Initial Params [3.15271655]\n",
      "Cost:  -70.3078599245161\n",
      "Initial Params [3.15271654]\n",
      "Cost:  -70.30785993285829\n",
      "Initial Params [3.12906522]\n",
      "Cost:  -70.3066151583612\n",
      "Initial Params [3.12906523]\n",
      "Cost:  -70.3066151677558\n",
      "Initial Params [3.14159275]\n",
      "Cost:  -70.3124999999996\n",
      "Initial Params [3.14159276]\n",
      "Cost:  -70.31249999999955\n",
      "Initial Params [3.14159275]\n",
      "Cost:  -70.3124999999996\n",
      "Optimized theta values: [3.14159275]\n",
      "Cost function after optimization: -70.3124999999996\n",
      "Optimized Theta Values:  [-0.6971822506393264, 0, -3.141592594918539, 3.1415927511655]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 4 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:4\n",
      "Circuit Depth: 27\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.1599999999999986, 'YZ': 0.1599999999999986, 'ZY': 0.15999999999999975, 'ZYZ': 0.15999999999999936}\n",
      "Maximum Gradient:  0.15999999999999975\n",
      "Operator with largest gradient: ZY, Gradient: 0.15999999999999975\n",
      "The current operator (ZY) is different from the last applied operator (ZYZ).\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_2) ZY)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [2.90065519]\n",
      "Cost:  -68.17739276102832\n",
      "Initial Params [2.9006552]\n",
      "Cost:  -68.1773929348188\n",
      "Initial Params [3.90065519]\n",
      "Cost:  -52.54962733709902\n",
      "Initial Params [3.9006552]\n",
      "Cost:  -52.54962696261909\n",
      "Initial Params [3.11467107]\n",
      "Cost:  -70.2853277549597\n",
      "Initial Params [3.11467108]\n",
      "Cost:  -70.28532777514108\n",
      "Initial Params [3.11467107]\n",
      "Cost:  -70.2853277549597\n",
      "Initial Params [3.1427888]\n",
      "Cost:  -70.3124463413286\n",
      "Initial Params [3.14278881]\n",
      "Cost:  -70.31244634043145\n",
      "Initial Params [3.1427888]\n",
      "Cost:  -70.3124463413286\n",
      "Initial Params [3.14159205]\n",
      "Cost:  -70.31249999998855\n",
      "Initial Params [3.14159206]\n",
      "Cost:  -70.31249999998893\n",
      "Initial Params [3.14159205]\n",
      "Cost:  -70.31249999998855\n",
      "Initial Params [3.14159256]\n",
      "Cost:  -70.31249999999966\n",
      "Initial Params [3.14159257]\n",
      "Cost:  -70.31249999999967\n",
      "Initial Params [3.14159256]\n",
      "Cost:  -70.31249999999966\n",
      "Optimized theta values: [3.14159256]\n",
      "Cost function after optimization: -70.31249999999966\n",
      "Optimized Theta Values:  [-0.6971822506393264, 0, 3.1415925605719726, 3.1415927511655]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 5 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:5\n",
      "Circuit Depth: 34\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.1599999999999986, 'YZ': 0.1599999999999986, 'ZY': 0.1599999999999997, 'ZYZ': 0.1599999999999993}\n",
      "Maximum Gradient:  0.1599999999999997\n",
      "Operator with largest gradient: ZY, Gradient: 0.1599999999999997\n",
      "Warning: The current operator (ZY) is the same as the last applied operator.\n",
      "Applying the second largest gradient operator instead: ZYZ, Gradient: 0.1599999999999993\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_3) ZYZ)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [-2.26498338]\n",
      "Cost:  -48.161019966155145\n",
      "Initial Params [-2.26498337]\n",
      "Cost:  -48.161019597377496\n",
      "Initial Params [-3.26498338]\n",
      "Cost:  -69.74444469403473\n",
      "Initial Params [-3.26498337]\n",
      "Cost:  -69.74444478564125\n",
      "Initial Params [-3.26498338]\n",
      "Cost:  -69.74444469403473\n",
      "Initial Params [-3.06600494]\n",
      "Cost:  -70.09865102006061\n",
      "Initial Params [-3.06600493]\n",
      "Cost:  -70.09865096358547\n",
      "Initial Params [-3.06600494]\n",
      "Cost:  -70.09865102006061\n",
      "Initial Params [-3.14189101]\n",
      "Cost:  -70.31249666334595\n",
      "Initial Params [-3.141891]\n",
      "Cost:  -70.31249666356966\n",
      "Initial Params [-3.14189101]\n",
      "Cost:  -70.31249666334595\n",
      "Initial Params [-3.1415916]\n",
      "Cost:  -70.31249999995276\n",
      "Initial Params [-3.14159159]\n",
      "Cost:  -70.31249999995194\n",
      "Initial Params [-3.1415916]\n",
      "Cost:  -70.31249999995276\n",
      "Initial Params [-3.1415927]\n",
      "Cost:  -70.31249999999982\n",
      "Initial Params [-3.14159269]\n",
      "Cost:  -70.31249999999979\n",
      "Initial Params [-3.1415927]\n",
      "Cost:  -70.31249999999982\n",
      "Optimized theta values: [-3.1415927]\n",
      "Cost function after optimization: -70.31249999999982\n",
      "Optimized Theta Values:  [-0.6971822506393264, 0, 3.1415925605719726, -3.1415927016738854]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 6 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:6\n",
      "Circuit Depth: 43\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.15999999999999956, 'YZ': 0.15999999999999956, 'ZY': 0.15999999999999967, 'ZYZ': 0.15999999999999964}\n",
      "Maximum Gradient:  0.15999999999999967\n",
      "Operator with largest gradient: ZY, Gradient: 0.15999999999999967\n",
      "The current operator (ZY) is different from the last applied operator (ZYZ).\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_2) ZY)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [-2.87612925]\n",
      "Cost:  -67.73134137813108\n",
      "Initial Params [-2.87612924]\n",
      "Cost:  -67.73134118825627\n",
      "Initial Params [-3.87612925]\n",
      "Cost:  -53.46651969266692\n",
      "Initial Params [-3.87612924]\n",
      "Cost:  -53.46652006572844\n",
      "Initial Params [-3.11460116]\n",
      "Cost:  -70.28518641837124\n",
      "Initial Params [-3.11460115]\n",
      "Cost:  -70.28518639813744\n",
      "Initial Params [-3.11460116]\n",
      "Cost:  -70.28518641837124\n",
      "Initial Params [-3.14304471]\n",
      "Cost:  -70.312420929304\n",
      "Initial Params [-3.1430447]\n",
      "Cost:  -70.31242093039307\n",
      "Initial Params [-3.14304471]\n",
      "Cost:  -70.312420929304\n",
      "Initial Params [-3.14159194]\n",
      "Cost:  -70.31249999998232\n",
      "Initial Params [-3.14159193]\n",
      "Cost:  -70.31249999998178\n",
      "Initial Params [-3.14159194]\n",
      "Cost:  -70.31249999998232\n",
      "Initial Params [-3.14159266]\n",
      "Cost:  -70.31249999999977\n",
      "Initial Params [-3.14159265]\n",
      "Cost:  -70.31249999999983\n",
      "Initial Params [-3.14159266]\n",
      "Cost:  -70.31249999999977\n",
      "Optimized theta values: [-3.14159266]\n",
      "Cost function after optimization: -70.31249999999977\n",
      "Optimized Theta Values:  [-0.6971822506393264, 0, -3.1415926556484277, -3.1415927016738854]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 7 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:7\n",
      "Circuit Depth: 50\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.15999999999999948, 'YZ': 0.15999999999999948, 'ZY': 0.1599999999999996, 'ZYZ': 0.15999999999999953}\n",
      "Maximum Gradient:  0.1599999999999996\n",
      "Operator with largest gradient: ZY, Gradient: 0.1599999999999996\n",
      "Warning: The current operator (ZY) is the same as the last applied operator.\n",
      "Applying the second largest gradient operator instead: ZYZ, Gradient: 0.15999999999999953\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_3) ZYZ)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [1.3005034]\n",
      "Cost:  -35.48611227055723\n",
      "Initial Params [1.30050341]\n",
      "Cost:  -35.486112077567846\n",
      "Initial Params [0.3005034]\n",
      "Cost:  -67.02687549205909\n",
      "Initial Params [0.30050341]\n",
      "Cost:  -67.02687528000665\n",
      "Initial Params [-3.6994966]\n",
      "Cost:  -59.80222423170043\n",
      "Initial Params [-3.69949659]\n",
      "Cost:  -59.80222456855022\n",
      "Initial Params [-1.63591688]\n",
      "Cost:  -32.971300954510404\n",
      "Initial Params [-1.63591687]\n",
      "Cost:  -32.97130090580798\n",
      "Initial Params [0.07010091]\n",
      "Cost:  -70.12852141670918\n",
      "Initial Params [0.07010092]\n",
      "Cost:  -70.12852136430554\n",
      "Initial Params [0.07010091]\n",
      "Cost:  -70.12852141670918\n",
      "Initial Params [-0.38853423]\n",
      "Cost:  -64.93072885601299\n",
      "Initial Params [-0.38853422]\n",
      "Cost:  -64.9307291189601\n",
      "Initial Params [0.00270365]\n",
      "Cost:  -70.31222588178035\n",
      "Initial Params [0.00270366]\n",
      "Cost:  -70.3122258797526\n",
      "Initial Params [0.00270365]\n",
      "Cost:  -70.31222588178035\n",
      "Initial Params [-9.24665178e-06]\n",
      "Cost:  -70.31249999680816\n",
      "Initial Params [-9.23665178e-06]\n",
      "Cost:  -70.31249999681503\n",
      "Initial Params [-9.24665178e-06]\n",
      "Cost:  -70.31249999680816\n",
      "Initial Params [-7.56995075e-08]\n",
      "Cost:  -70.31249999999963\n",
      "Initial Params [-6.56995075e-08]\n",
      "Cost:  -70.31249999999969\n",
      "Initial Params [-7.56995075e-08]\n",
      "Cost:  -70.31249999999963\n",
      "Optimized theta values: [-7.56995075e-08]\n",
      "Cost function after optimization: -70.31249999999963\n",
      "Optimized Theta Values:  [-0.6971822506393264, 0, -3.1415926556484277, -7.569950750430222e-08]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 8 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:8\n",
      "Circuit Depth: 59\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.15999999999999875, 'YZ': 0.15999999999999875, 'ZY': 0.15999999999999948, 'ZYZ': 0.15999999999999925}\n",
      "Maximum Gradient:  0.15999999999999948\n",
      "Operator with largest gradient: ZY, Gradient: 0.15999999999999948\n",
      "The current operator (ZY) is different from the last applied operator (ZYZ).\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_2) ZY)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [-3.1196073]\n",
      "Cost:  -70.29437713332771\n",
      "Initial Params [-3.11960729]\n",
      "Cost:  -70.29437711684403\n",
      "Initial Params [-4.1196073]\n",
      "Cost:  -44.5167168662985\n",
      "Initial Params [-4.11960729]\n",
      "Cost:  -44.516717213815085\n",
      "Initial Params [-3.137771]\n",
      "Cost:  -70.31195232552754\n",
      "Initial Params [-3.13777099]\n",
      "Cost:  -70.31195232266136\n",
      "Initial Params [-3.137771]\n",
      "Cost:  -70.31195232552754\n",
      "Initial Params [-3.14159407]\n",
      "Cost:  -70.3124999999204\n",
      "Initial Params [-3.14159406]\n",
      "Cost:  -70.31249999992151\n",
      "Initial Params [-3.14159407]\n",
      "Cost:  -70.3124999999204\n",
      "Initial Params [-3.14159259]\n",
      "Cost:  -70.31249999999964\n",
      "Initial Params [-3.14159258]\n",
      "Cost:  -70.31249999999964\n",
      "Initial Params [-3.14159259]\n",
      "Cost:  -70.31249999999964\n",
      "Optimized theta values: [-3.14159259]\n",
      "Cost function after optimization: -70.31249999999964\n",
      "Optimized Theta Values:  [-0.6971822506393264, 0, -3.141592593086952, -7.569950750430222e-08]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 9 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:9\n",
      "Circuit Depth: 66\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.15999999999999867, 'YZ': 0.15999999999999867, 'ZY': 0.1599999999999994, 'ZYZ': 0.15999999999999914}\n",
      "Maximum Gradient:  0.1599999999999994\n",
      "Operator with largest gradient: ZY, Gradient: 0.1599999999999994\n",
      "Warning: The current operator (ZY) is the same as the last applied operator.\n",
      "Applying the second largest gradient operator instead: ZYZ, Gradient: 0.15999999999999914\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_3) ZYZ)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [-0.46844379]\n",
      "Cost:  -62.66809767764916\n",
      "Initial Params [-0.46844378]\n",
      "Cost:  -62.66809797979363\n",
      "Initial Params [0.53155621]\n",
      "Cost:  -60.67790006365121\n",
      "Initial Params [0.53155622]\n",
      "Cost:  -60.6778997359489\n",
      "Initial Params [-0.00560281]\n",
      "Cost:  -70.31132280848178\n",
      "Initial Params [-0.0056028]\n",
      "Cost:  -70.31132281268385\n",
      "Initial Params [-0.00560281]\n",
      "Cost:  -70.31132280848178\n",
      "Initial Params [0.00092494]\n",
      "Cost:  -70.31246792191402\n",
      "Initial Params [0.00092495]\n",
      "Cost:  -70.31246792122036\n",
      "Initial Params [0.00092494]\n",
      "Cost:  -70.31246792191402\n",
      "Initial Params [4.69290851e-08]\n",
      "Cost:  -70.31249999999974\n",
      "Initial Params [5.69290851e-08]\n",
      "Cost:  -70.31249999999974\n",
      "Initial Params [4.69290851e-08]\n",
      "Cost:  -70.31249999999974\n",
      "Optimized theta values: [4.69290851e-08]\n",
      "Cost function after optimization: -70.31249999999974\n",
      "Optimized Theta Values:  [-0.6971822506393264, 0, -3.141592593086952, 4.692908512054367e-08]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 10 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:10\n",
      "Circuit Depth: 75\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.15999999999999934, 'YZ': 0.15999999999999934, 'ZY': 0.15999999999999936, 'ZYZ': 0.15999999999999936}\n",
      "Maximum Gradient:  0.15999999999999936\n",
      "Operator with largest gradient: ZY, Gradient: 0.15999999999999936\n",
      "The current operator (ZY) is different from the last applied operator (ZYZ).\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_2) ZY)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [-1.60474185]\n",
      "Cost:  -32.85569453755814\n",
      "Initial Params [-1.60474184]\n",
      "Cost:  -32.85569451211857\n",
      "Initial Params [-2.60474185]\n",
      "Cost:  -60.50388472282789\n",
      "Initial Params [-2.60474184]\n",
      "Cost:  -60.5038843932135\n",
      "Initial Params [-6.60474185]\n",
      "Cost:  -66.56686468854014\n",
      "Initial Params [-6.60474184]\n",
      "Cost:  -66.5668649134237\n",
      "Initial Params [-4.57994139]\n",
      "Cost:  -33.46650118745778\n",
      "Initial Params [-4.57994138]\n",
      "Cost:  -33.46650128563583\n",
      "Initial Params [-6.35702565]\n",
      "Cost:  -70.10840659877876\n",
      "Initial Params [-6.35702564]\n",
      "Cost:  -70.10840665395791\n",
      "Initial Params [-6.28597326]\n",
      "Cost:  -70.31220853014929\n",
      "Initial Params [-6.28597325]\n",
      "Cost:  -70.31220853224022\n",
      "Initial Params [-6.28597326]\n",
      "Cost:  -70.31220853014929\n",
      "Initial Params [-5.93043602]\n",
      "Cost:  -65.83665635526812\n",
      "Initial Params [-5.93043601]\n",
      "Cost:  -65.83665611211306\n",
      "Initial Params [-6.28329046]\n",
      "Cost:  -70.31249958553418\n",
      "Initial Params [-6.28329045]\n",
      "Cost:  -70.31249958561303\n",
      "Initial Params [-6.28329046]\n",
      "Cost:  -70.31249958553418\n",
      "Initial Params [-6.28318534]\n",
      "Cost:  -70.31249999999976\n",
      "Initial Params [-6.28318533]\n",
      "Cost:  -70.31249999999976\n",
      "Initial Params [-6.28318534]\n",
      "Cost:  -70.31249999999976\n",
      "Optimized theta values: [-6.28318534]\n",
      "Cost function after optimization: -70.31249999999976\n",
      "Optimized Theta Values:  [-0.6971822506393264, 0, -6.283185338658922, 4.692908512054367e-08]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 11 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:11\n",
      "Circuit Depth: 82\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.1599999999999993, 'YZ': 0.1599999999999993, 'ZY': 0.1599999999999993, 'ZYZ': 0.1599999999999993}\n",
      "Maximum Gradient:  0.1599999999999993\n",
      "Operator with largest gradient: Y, Gradient: 0.1599999999999993\n",
      "The current operator (Y) is different from the last applied operator (ZY).\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_0) Y)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [-1.7128731]\n",
      "Cost:  -70.31250000034188\n",
      "Initial Params [-1.71287309]\n",
      "Cost:  -70.31250000034187\n",
      "Optimized theta values: [-1.7128731]\n",
      "Cost function after optimization: -70.31250000034188\n",
      "Optimized Theta Values:  [-1.7128730959126472, 0, -6.283185338658922, 4.692908512054367e-08]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 12 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:12\n",
      "Circuit Depth: 83\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.1599999999999993, 'YZ': 0.1599999999999993, 'ZY': 0.1599999999999993, 'ZYZ': 0.1599999999999993}\n",
      "Maximum Gradient:  0.1599999999999993\n",
      "Operator with largest gradient: Y, Gradient: 0.1599999999999993\n",
      "Warning: The current operator (Y) is the same as the last applied operator.\n",
      "Applying the second largest gradient operator instead: ZYZ, Gradient: 0.1599999999999993\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_3) ZYZ)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [1.48912433]\n",
      "Cost:  -33.06208111113838\n",
      "Initial Params [1.48912434]\n",
      "Cost:  -33.062081050156415\n",
      "Initial Params [0.48912433]\n",
      "Cost:  -62.033928105921476\n",
      "Initial Params [0.48912434]\n",
      "Cost:  -62.03392779485129\n",
      "Initial Params [-3.51087567]\n",
      "Cost:  -65.42690087897955\n",
      "Initial Params [-3.51087566]\n",
      "Cost:  -65.42690113144015\n",
      "Initial Params [-1.49719558]\n",
      "Cost:  -33.015273645769916\n",
      "Initial Params [-1.49719557]\n",
      "Cost:  -33.01527370077139\n",
      "Initial Params [-3.23220625]\n",
      "Cost:  -70.00543594206786\n",
      "Initial Params [-3.23220624]\n",
      "Cost:  -70.00543600965663\n",
      "Initial Params [-3.1459891]\n",
      "Cost:  -70.31177517912427\n",
      "Initial Params [-3.14598909]\n",
      "Cost:  -70.31177518242151\n",
      "Initial Params [-3.1459891]\n",
      "Cost:  -70.31177517912427\n",
      "Initial Params [-2.90822786]\n",
      "Cost:  -68.30708699583089\n",
      "Initial Params [-2.90822785]\n",
      "Cost:  -68.30708682709286\n",
      "Initial Params [-3.14166811]\n",
      "Cost:  -70.31249978684252\n",
      "Initial Params [-3.1416681]\n",
      "Cost:  -70.31249978689907\n",
      "Initial Params [-3.14166811]\n",
      "Cost:  -70.31249978684252\n",
      "Initial Params [-3.14159272]\n",
      "Cost:  -70.31250000034169\n",
      "Initial Params [-3.14159271]\n",
      "Cost:  -70.31250000034173\n",
      "Initial Params [-3.14159272]\n",
      "Cost:  -70.31250000034169\n",
      "Optimized theta values: [-3.14159272]\n",
      "Cost function after optimization: -70.31250000034169\n",
      "Optimized Theta Values:  [-1.7128730959126472, 0, -6.283185338658922, -3.1415927207287684]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 13 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:13\n",
      "Circuit Depth: 92\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.15999999999999837, 'YZ': 0.15999999999999837, 'ZY': 0.15999999999999923, 'ZYZ': 0.15999999999999895}\n",
      "Maximum Gradient:  0.15999999999999923\n",
      "Operator with largest gradient: ZY, Gradient: 0.15999999999999923\n",
      "The current operator (ZY) is different from the last applied operator (ZYZ).\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_2) ZY)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [-1.91576277]\n",
      "Cost:  -37.1008364352982\n",
      "Initial Params [-1.91576276]\n",
      "Cost:  -37.10083619661617\n",
      "Initial Params [-2.91576277]\n",
      "Cost:  -68.43232364659822\n",
      "Initial Params [-2.91576276]\n",
      "Cost:  -68.43232348292592\n",
      "Initial Params [-2.91576277]\n",
      "Cost:  -68.43232364659822\n",
      "Initial Params [-5.09777699]\n",
      "Cost:  -38.111808079424485\n",
      "Initial Params [-5.09777698]\n",
      "Cost:  -38.11180781816492\n",
      "Initial Params [-3.11183133]\n",
      "Cost:  -70.27929470610354\n",
      "Initial Params [-3.11183132]\n",
      "Cost:  -70.27929468379574\n",
      "Initial Params [-3.11183133]\n",
      "Cost:  -70.27929470610354\n",
      "Initial Params [-3.14277162]\n",
      "Cost:  -70.31244787617321\n",
      "Initial Params [-3.14277161]\n",
      "Cost:  -70.31244787705745\n",
      "Initial Params [-3.14277162]\n",
      "Cost:  -70.31244787617321\n",
      "Initial Params [-3.14159196]\n",
      "Cost:  -70.31250000032405\n",
      "Initial Params [-3.14159195]\n",
      "Cost:  -70.31250000032354\n",
      "Initial Params [-3.14159196]\n",
      "Cost:  -70.31250000032405\n",
      "Initial Params [-3.14159264]\n",
      "Cost:  -70.31250000034167\n",
      "Initial Params [-3.14159263]\n",
      "Cost:  -70.31250000034167\n",
      "Initial Params [-3.14159264]\n",
      "Cost:  -70.31250000034167\n",
      "Optimized theta values: [-3.14159264]\n",
      "Cost function after optimization: -70.31250000034167\n",
      "Optimized Theta Values:  [-1.7128730959126472, 0, -3.141592642737617, -3.1415927207287684]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 14 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:14\n",
      "Circuit Depth: 99\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.15999999999999828, 'YZ': 0.15999999999999828, 'ZY': 0.15999999999999914, 'ZYZ': 0.15999999999999887}\n",
      "Maximum Gradient:  0.15999999999999914\n",
      "Operator with largest gradient: ZY, Gradient: 0.15999999999999914\n",
      "Warning: The current operator (ZY) is the same as the last applied operator.\n",
      "Applying the second largest gradient operator instead: ZYZ, Gradient: 0.15999999999999887\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_3) ZYZ)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [1.28781202]\n",
      "Cost:  -35.73619641172089\n",
      "Initial Params [1.28781203]\n",
      "Cost:  -35.736196210633246\n",
      "Initial Params [0.28781202]\n",
      "Cost:  -67.29099063704518\n",
      "Initial Params [0.28781203]\n",
      "Cost:  -67.29099043291083\n",
      "Initial Params [-3.71218798]\n",
      "Cost:  -59.37210421858444\n",
      "Initial Params [-3.71218797]\n",
      "Cost:  -59.37210455950824\n",
      "Initial Params [-1.64022585]\n",
      "Cost:  -32.99297723651924\n",
      "Initial Params [-1.64022584]\n",
      "Cost:  -32.992977184614226\n",
      "Initial Params [0.06630468]\n",
      "Cost:  -70.14788011117557\n",
      "Initial Params [0.06630469]\n",
      "Cost:  -70.14788006159274\n",
      "Initial Params [0.06630468]\n",
      "Cost:  -70.14788011117557\n",
      "Initial Params [-0.33345674]\n",
      "Cost:  -66.29502268565969\n",
      "Initial Params [-0.33345673]\n",
      "Cost:  -66.29502291762113\n",
      "Initial Params [0.00187949]\n",
      "Cost:  -70.3123675406543\n",
      "Initial Params [0.0018795]\n",
      "Cost:  -70.31236753924472\n",
      "Initial Params [0.00187949]\n",
      "Cost:  -70.3123675406543\n",
      "Initial Params [-5.62373153e-06]\n",
      "Cost:  -70.31249999913044\n",
      "Initial Params [-5.61373153e-06]\n",
      "Cost:  -70.31249999913472\n",
      "Initial Params [-5.62373153e-06]\n",
      "Cost:  -70.31249999913044\n",
      "Initial Params [7.94939714e-08]\n",
      "Cost:  -70.31250000034179\n",
      "Initial Params [8.94939714e-08]\n",
      "Cost:  -70.31250000034174\n",
      "Initial Params [7.94939714e-08]\n",
      "Cost:  -70.31250000034179\n",
      "Optimized theta values: [7.94939714e-08]\n",
      "Cost function after optimization: -70.31250000034179\n",
      "Optimized Theta Values:  [-1.7128730959126472, 0, -3.141592642737617, 7.949397140540361e-08]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 15 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:15\n",
      "Circuit Depth: 108\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.159999999999999, 'YZ': 0.159999999999999, 'ZY': 0.15999999999999912, 'ZYZ': 0.1599999999999991}\n",
      "Maximum Gradient:  0.15999999999999912\n",
      "Operator with largest gradient: ZY, Gradient: 0.15999999999999912\n",
      "The current operator (ZY) is different from the last applied operator (ZYZ).\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_2) ZY)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [2.58967766]\n",
      "Cost:  -60.0033655688772\n",
      "Initial Params [2.58967767]\n",
      "Cost:  -60.003365903729005\n",
      "Initial Params [3.58967766]\n",
      "Cost:  -63.27385364745486\n",
      "Initial Params [3.58967767]\n",
      "Cost:  -63.273853354602196\n",
      "Initial Params [3.58967766]\n",
      "Cost:  -63.27385364745486\n",
      "Initial Params [3.12313221]\n",
      "Cost:  -70.29972191123169\n",
      "Initial Params [3.12313222]\n",
      "Cost:  -70.29972192507384\n",
      "Initial Params [3.12313221]\n",
      "Cost:  -70.29972191123169\n",
      "Initial Params [3.14418896]\n",
      "Cost:  -70.31224722078278\n",
      "Initial Params [3.14418897]\n",
      "Cost:  -70.31224721883555\n",
      "Initial Params [3.14418896]\n",
      "Cost:  -70.31224722078278\n",
      "Initial Params [3.14159213]\n",
      "Cost:  -70.3125000003316\n",
      "Initial Params [3.14159214]\n",
      "Cost:  -70.312500000332\n",
      "Initial Params [3.14159213]\n",
      "Cost:  -70.3125000003316\n",
      "Initial Params [3.14159266]\n",
      "Cost:  -70.31250000034177\n",
      "Initial Params [3.14159267]\n",
      "Cost:  -70.31250000034176\n",
      "Initial Params [3.14159266]\n",
      "Cost:  -70.31250000034177\n",
      "Optimized theta values: [3.14159266]\n",
      "Cost function after optimization: -70.31250000034177\n",
      "Optimized Theta Values:  [-1.7128730959126472, 0, 3.1415926600602466, 7.949397140540361e-08]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 16 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:16\n",
      "Circuit Depth: 115\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.15999999999999895, 'YZ': 0.15999999999999895, 'ZY': 0.15999999999999906, 'ZYZ': 0.15999999999999903}\n",
      "Maximum Gradient:  0.15999999999999906\n",
      "Operator with largest gradient: ZY, Gradient: 0.15999999999999906\n",
      "Warning: The current operator (ZY) is the same as the last applied operator.\n",
      "Applying the second largest gradient operator instead: ZYZ, Gradient: 0.15999999999999903\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_3) ZYZ)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [2.84162351]\n",
      "Cost:  -67.03819658839069\n",
      "Initial Params [2.84162352]\n",
      "Cost:  -67.0381968001125\n",
      "Initial Params [3.84162351]\n",
      "Cost:  -54.748242804236604\n",
      "Initial Params [3.84162352]\n",
      "Cost:  -54.74824243468901\n",
      "Initial Params [3.11555785]\n",
      "Cost:  -70.28708786541699\n",
      "Initial Params [3.11555786]\n",
      "Cost:  -70.28708788493424\n",
      "Initial Params [3.11555785]\n",
      "Cost:  -70.28708786541699\n",
      "Initial Params [3.14337427]\n",
      "Cost:  -70.31238096682603\n",
      "Initial Params [3.14337428]\n",
      "Cost:  -70.3123809654898\n",
      "Initial Params [3.14337427]\n",
      "Cost:  -70.31238096682603\n",
      "Initial Params [3.14159187]\n",
      "Cost:  -70.31250000032003\n",
      "Initial Params [3.14159188]\n",
      "Cost:  -70.3125000003206\n",
      "Initial Params [3.14159187]\n",
      "Cost:  -70.31250000032003\n",
      "Initial Params [3.14159263]\n",
      "Cost:  -70.31250000034176\n",
      "Initial Params [3.14159264]\n",
      "Cost:  -70.31250000034171\n",
      "Initial Params [3.14159263]\n",
      "Cost:  -70.31250000034176\n",
      "Optimized theta values: [3.14159263]\n",
      "Cost function after optimization: -70.31250000034176\n",
      "Optimized Theta Values:  [-1.7128730959126472, 0, 3.1415926600602466, 3.141592630323705]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 17 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:17\n",
      "Circuit Depth: 124\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.15999999999999903, 'YZ': 0.15999999999999903, 'ZY': 0.15999999999999903, 'ZYZ': 0.15999999999999903}\n",
      "Maximum Gradient:  0.15999999999999903\n",
      "Operator with largest gradient: Y, Gradient: 0.15999999999999903\n",
      "The current operator (Y) is different from the last applied operator (ZYZ).\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_0) Y)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [3.08284364]\n",
      "Cost:  -70.31250000027205\n",
      "Initial Params [3.08284365]\n",
      "Cost:  -70.31250000027205\n",
      "Optimized theta values: [3.08284364]\n",
      "Cost function after optimization: -70.31250000027205\n",
      "Optimized Theta Values:  [3.082843644484994, 0, 3.1415926600602466, 3.141592630323705]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 18 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:18\n",
      "Circuit Depth: 125\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.15999999999999906, 'YZ': 0.15999999999999906, 'ZY': 0.15999999999999906, 'ZYZ': 0.15999999999999906}\n",
      "Maximum Gradient:  0.15999999999999906\n",
      "Operator with largest gradient: Y, Gradient: 0.15999999999999906\n",
      "Warning: The current operator (Y) is the same as the last applied operator.\n",
      "Applying the second largest gradient operator instead: ZYZ, Gradient: 0.15999999999999906\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_3) ZYZ)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [0.66158071]\n",
      "Cost:  -56.15834449100708\n",
      "Initial Params [0.66158072]\n",
      "Cost:  -56.158344127446526\n",
      "Initial Params [-0.33841929]\n",
      "Cost:  -66.17918822568488\n",
      "Initial Params [-0.33841928]\n",
      "Cost:  -66.17918846055927\n",
      "Initial Params [-0.33841929]\n",
      "Cost:  -66.17918822568488\n",
      "Initial Params [0.05406179]\n",
      "Cost:  -70.20300635520331\n",
      "Initial Params [0.0540618]\n",
      "Cost:  -70.2030063147359\n",
      "Initial Params [0.05406179]\n",
      "Cost:  -70.20300635520331\n",
      "Initial Params [-0.00362176]\n",
      "Cost:  -70.31200810757466\n",
      "Initial Params [-0.00362175]\n",
      "Cost:  -70.31200811029096\n",
      "Initial Params [-0.00362176]\n",
      "Cost:  -70.31200810757466\n",
      "Initial Params [6.59855245e-06]\n",
      "Cost:  -70.31249999864112\n",
      "Initial Params [6.60855245e-06]\n",
      "Cost:  -70.31249999863616\n",
      "Initial Params [6.59855245e-06]\n",
      "Cost:  -70.31249999864112\n",
      "Initial Params [-1.42472172e-08]\n",
      "Cost:  -70.312500000272\n",
      "Initial Params [-4.2472172e-09]\n",
      "Cost:  -70.31250000027202\n",
      "Initial Params [-1.42472172e-08]\n",
      "Cost:  -70.312500000272\n",
      "Optimized theta values: [-1.42472172e-08]\n",
      "Cost function after optimization: -70.312500000272\n",
      "Optimized Theta Values:  [3.082843644484994, 0, 3.1415926600602466, -1.4247217196133313e-08]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 19 iterations! <<<\n",
      "====================================================================================================\n",
      "===========>>> Initializing the Ansatz / Ansatz Info <<<============\n",
      ">>> Iteration:19\n",
      "Circuit Depth: 134\n",
      "===========>>> Finding An Operator with Maximum Gradient Norm <<<============\n",
      "Gradients:  {'Y': 0.15999999999999892, 'YZ': 0.15999999999999892, 'ZY': 0.15999999999999898, 'ZYZ': 0.15999999999999898}\n",
      "Maximum Gradient:  0.15999999999999898\n",
      "Operator with largest gradient: ZY, Gradient: 0.15999999999999898\n",
      "The current operator (ZY) is different from the last applied operator (ZYZ).\n",
      "===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\n",
      "=========================\n",
      "==> Applied Unitary: exp(-i (theta_2) ZY)\n",
      "=========================\n",
      "Number of Parameters:  1\n",
      "Initial Params [1.48251577]\n",
      "Cost:  -33.10399611684369\n",
      "Initial Params [1.48251578]\n",
      "Cost:  -33.10399605097676\n",
      "Initial Params [0.48251577]\n",
      "Cost:  -62.23857994147761\n",
      "Initial Params [0.48251578]\n",
      "Cost:  -62.23857963320253\n",
      "Initial Params [-3.51748423]\n",
      "Cost:  -65.25885479053196\n",
      "Initial Params [-3.51748422]\n",
      "Cost:  -65.25885504663536\n",
      "Initial Params [-1.50532317]\n",
      "Cost:  -32.97302303659736\n",
      "Initial Params [-1.50532316]\n",
      "Cost:  -32.97302308556203\n",
      "Initial Params [-3.23448792]\n",
      "Cost:  -69.98982247995009\n",
      "Initial Params [-3.23448791]\n",
      "Cost:  -69.9898225492214\n",
      "Initial Params [-3.14624245]\n",
      "Cost:  -70.31168923510343\n",
      "Initial Params [-3.14624244]\n",
      "Cost:  -70.3116892385907\n",
      "Initial Params [-3.14624245]\n",
      "Cost:  -70.31168923510343\n",
      "Initial Params [-2.91349891]\n",
      "Cost:  -68.39509752586271\n",
      "Initial Params [-2.9134989]\n",
      "Cost:  -68.39509736066445\n",
      "Initial Params [-3.14166889]\n",
      "Cost:  -70.31249978237487\n",
      "Initial Params [-3.14166888]\n",
      "Cost:  -70.31249978243204\n",
      "Initial Params [-3.14166889]\n",
      "Cost:  -70.31249978237487\n",
      "Initial Params [-3.14159266]\n",
      "Cost:  -70.31250000027198\n",
      "Initial Params [-3.14159265]\n",
      "Cost:  -70.31250000027198\n",
      "Initial Params [-3.14159266]\n",
      "Cost:  -70.31250000027198\n",
      "Optimized theta values: [-3.14159266]\n",
      "Cost function after optimization: -70.31250000027198\n",
      "Optimized Theta Values:  [3.082843644484994, 0, -3.1415926621587236, -1.4247217196133313e-08]\n",
      "===========>>> Updating Ansatz with Optimized Parameters <<<============\n",
      "Overlap with Exact GS: 99.998%\n",
      ">>> Did NOT converge in 20 iterations! <<<\n",
      "====================================================================================================\n",
      "\n",
      " Final Expectation Value of the Total Hamiltonian: -70.31250000027192\n",
      "\n",
      " Exact Energy of GS of H_tot: -70.31335332427172\n",
      "=================================== >> DONE << ===================================\n"
     ]
    }
   ],
   "source": [
    "###### PERFORMING ADAPT-VQE #######\n",
    "\n",
    "### Define constants\n",
    "N = 5 # Number of spins\n",
    "a = 1.0  # Lattice spacing\n",
    "\n",
    "# coupling constants \n",
    "g = 2.0\n",
    "\n",
    "# Calculate Hamiltonian parameters\n",
    "J = -3 * g**2 / 16\n",
    "hz = 3 * g**2 / 8\n",
    "hx = -2 / (a * g)**2 \n",
    "\n",
    "print(\"=\"*100)\n",
    "print(f\"Spins (N): {N}, Coupling (g) : {g}\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Calculate Hamiltonian\n",
    "H_E = hamiltonian_elec(N, J, hz)\n",
    "H_M = hamiltonian_mag(N, hx)\n",
    "H_tot = H_E + H_M\n",
    "\n",
    "# Exact Ground State Energy of H_tot\n",
    "_, _, gs_exact, psi_realgs = exact_ground_state(H_tot)\n",
    "\n",
    "print(\"Exact Ground State Energy of The Total Hamiltonian: \", gs_exact)\n",
    "\n",
    "# print(f\"Commutators of the Observables: {commutator_hamiltonian(H_tot, observable_pool)}\")\n",
    "\n",
    "## ADAPT - VQE \n",
    "tolerance = 1e-3 # convergence threshold\n",
    "n_iter = 10 # no of iterations\n",
    "\n",
    "# Lattice Site (for Observable Pool & Unitary Application)\n",
    "lattice_site = 0\n",
    "\n",
    "# Step 1: Operator Pool\n",
    "print(f\"Selected Lattice Site: {lattice_site}\")\n",
    "operator_pool = define_operator_pool(lattice_site, N)\n",
    "\n",
    "# Initialize lists to store iteration & expectation values\n",
    "iterations = []\n",
    "expectation_energies = []\n",
    "# theta_vals = []  # Start with an empty list for theta values\n",
    "selected_operators = []  # To keep track of already selected operators\n",
    "last_applied_operator = None # Initialize a variable to store the last applied operator\n",
    "\n",
    "# Parameters\n",
    "theta_vals = [Parameter(\"theta_0\"), Parameter(\"theta_1\"), Parameter(\"theta_2\"), Parameter(\"theta_3\")] \n",
    "optimized_theta_vals = [0] * len(theta_vals)\n",
    "\n",
    "# initialize the reference state\n",
    "qc = initial_ref(N)\n",
    "\n",
    "## MAIN LOOP for ADAPT-VQE\n",
    "for iteration in range(n_iter):\n",
    "           \n",
    "    ### Step 2: Ansatz\n",
    "    print(\"===========>>> Initializing the Ansatz / Ansatz Info <<<============\")\n",
    "    # print(qc.draw())\n",
    "    print(f\">>> Iteration:{iteration}\")\n",
    "    print(f\"Circuit Depth: {qc.depth()}\")\n",
    "    \n",
    "    print(\"===========>>> Finding An Operator with Maximum Gradient Norm <<<============\")\n",
    "    ### Step 3: Measure the gradient (commutator expectation value) for each operator\n",
    "    gradients = measure_gradient(H_tot, operator_pool, qc)\n",
    "    print(\"Gradients: \", gradients)\n",
    "    print(\"Maximum Gradient: \", np.max(list(gradients.values())))\n",
    "\n",
    "    # Extract gradient values and corresponding keys (indices)\n",
    "    gradient_values = np.array(list(gradients.values()))\n",
    "    gradient_keys = list(gradients.keys())\n",
    "\n",
    "    ### Step 4: Find the operator with the largest commutator / Gradient\n",
    "    max_gradient_idx= np.argmax(gradient_values)\n",
    "    max_gradient_op = gradient_keys[max_gradient_idx]  # This is a string like 'Y', 'YZ', etc.\n",
    "    max_gradient = gradients[max_gradient_op]\n",
    "    \n",
    "    print(f\"Operator with largest gradient: {max_gradient_op}, Gradient: {max_gradient}\")\n",
    "\n",
    "    # Compare with the last applied operator\n",
    "    if last_applied_operator is not None:\n",
    "        if max_gradient_op == last_applied_operator:\n",
    "            print(f\"Warning: The current operator ({max_gradient_op}) is the same as the last applied operator.\")\n",
    "            \n",
    "            # Find the operator with the second largest gradient\n",
    "            sorted_indices = np.argsort(gradient_values)[::-1]  # Sort gradients in descending order\n",
    "            for idx in sorted_indices:\n",
    "                if gradient_keys[idx] != last_applied_operator:\n",
    "                    max_gradient_idx = idx\n",
    "                    max_gradient_op = gradient_keys[max_gradient_idx]\n",
    "                    max_gradient = gradient_values[max_gradient_idx]\n",
    "                    print(f\"Applying the second largest gradient operator instead: {max_gradient_op}, Gradient: {max_gradient}\")\n",
    "                    break\n",
    "        else:\n",
    "            print(f\"The current operator ({max_gradient_op}) is different from the last applied operator ({last_applied_operator}).\")\n",
    "    else:\n",
    "        print(\"This is the first iteration, so no previous operator to compare with.\")\n",
    "\n",
    "\n",
    "    # Update the last applied operator to the current one\n",
    "    last_applied_operator = max_gradient_op\n",
    "\n",
    "    # Store the chosen operators\n",
    "    selected_operators.append(max_gradient_op)\n",
    "    \n",
    "    if np.linalg.norm(gradient_values) < tolerance:\n",
    "        print(f\"Terminating: Pool Gradient Norm: {np.linalg.norm(gradient_values)} is below the threshold: {tolerance}.\")\n",
    "        break            \n",
    "  \n",
    "    ### Step 5: Use VQE to optimize theta values\n",
    "    print(\"===========>>> Performing VQE: Minimizing Cost & Optimizing Parameters <<<============\")\n",
    "    # Parameterized Ansatz After Applying Unitary corresponding to the Maximum gradient norm Operator \n",
    "    ansatz_to_optimize = apply_unitary(qc, lattice_site, theta_vals, max_gradient_idx)\n",
    "    print(\"Number of Parameters: \", ansatz_to_optimize.num_parameters)\n",
    "    # print(ansatz_to_optimize.draw())\n",
    "    ### PERFORM VQE: Optimizing the parameters: Minimize the Cost\n",
    "    # Initialize history tracking\n",
    "    cost_history = []\n",
    "    \n",
    "    def callback(x):\n",
    "        energy = cost_func_vqe(x, H_tot, ansatz_to_optimize)\n",
    "        cost_history.append(energy)\n",
    "    \n",
    "    ## Optimize the new theta value for the selected operator\n",
    "    ## scipy.optimize.minimize(func, x0, ...) or scipy.optimize.basinhopping\n",
    "    ## other options available: L-BFGS-B, COBYLA, BFGS, etc \n",
    "    # initial_theta_vals = [0.1]*ansatz_to_optimize.num_parameters\n",
    "    initial_theta_vals = np.random.uniform(-np.pi, np.pi, ansatz_to_optimize.num_parameters).tolist()\n",
    "    opt = minimize(cost_func_vqe, initial_theta_vals, args=(H_tot, ansatz_to_optimize), method='L-BFGS-B', callback=callback)\n",
    "    print(f\"Optimized theta values: {opt.x}\")\n",
    "    print(f\"Cost function after optimization: {opt.fun}\")\n",
    "\n",
    "    # update optimized_theta value\n",
    "    optimized_theta_vals[max_gradient_idx] = opt.x.item() if isinstance(opt.x, np.ndarray) else opt.x\n",
    "    print(\"Optimized Theta Values: \", optimized_theta_vals)\n",
    "    \n",
    "    ### Step 6: Update the ansatz with the operator that has the largest gradient\n",
    "    # bind parameters to create an optimized circuit\n",
    "    print(\"===========>>> Updating Ansatz with Optimized Parameters <<<============\")\n",
    "    qc = ansatz_to_optimize.assign_parameters(opt.x)\n",
    "    qc.barrier()\n",
    "    # print(qc.draw())\n",
    "    \n",
    "    # get the statevector\n",
    "    psi_adaptvqe = qi.Statevector.from_instruction(qc)\n",
    "    \n",
    "    # Calculate the overlap\n",
    "    print(f\"Overlap with Exact GS: {calc_overlap(psi_adaptvqe, psi_realgs)*100:.3f}%\")\n",
    "\n",
    "    # Store the iteration number and the expectation value\n",
    "    iterations.append(iteration + 1)\n",
    "    expectation_energies.append(result.fun)\n",
    "\n",
    "    ### CHECK CONVERGENCE\n",
    "    if np.abs(result.fun - gs_exact) < tolerance:\n",
    "        print(\"=\"*25)\n",
    "        print(f\"SUCCESSFULLY CONVERGED!!!\")\n",
    "        print(\"=\"*100)\n",
    "        break\n",
    "    else:\n",
    "        print(f\">>> Did NOT converge in {iteration+1} iterations! <<<\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "# Final results\n",
    "final_cost = measure_exact_expectation_value(qc, H_tot)\n",
    "print(f\"\\n Final Expectation Value of the Total Hamiltonian: {final_cost}\")\n",
    "print(f\"\\n Exact Energy of GS of H_tot: {gs_exact}\")\n",
    "print(\"=\"*35,\">> DONE <<\",\"=\"*35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fce28ad4-d1fc-42b5-976b-1054edfb3dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the convergence of ADAPT-VQE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, expectation_energies, marker='o', linestyle='-', color='b', label='ADAPT-VQE Energy')\n",
    "plt.axhline(y=gs_exact, color='r', linestyle='--', label='Exact Ground State Energy')\n",
    "plt.xlabel('Iteration')\n",
    "plt.xticks(iterations, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylabel('Total Expectation Energy')\n",
    "plt.title('Convergence of ADAPT-VQE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(f'adapt_vqe_convergence_site{lattice_site}.png', dpi=300)  # Save as PNG with 300 dpi\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2176a718-e09e-4d15-ab57-9c7512fedd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
